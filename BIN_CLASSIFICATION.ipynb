{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fc01f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7a8444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to  training dataset\n",
    "dataset_path = r\"D:\\Apil\\Broadway Classes\\AI CLASSES\\AI Project\\Binary Classification\\train\"\n",
    "\n",
    "# Constants\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "epochs = 30 \n",
    "learning_rate = 0.0001  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0594d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the dataset\n",
    "def load_and_preprocess_dataset(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    class_labels = {'cat': 0, 'dog': 1}  # Map class labels to numeric values\n",
    "    \n",
    "    for label in os.listdir(dataset_path):\n",
    "        label_path = os.path.join(dataset_path, label)\n",
    "        for img_file in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0  # Normalize pixel values to be between 0 and 1\n",
    "            data.append(img)\n",
    "            labels.append(class_labels[label])\n",
    "\n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69f172a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocess the dataset\n",
    "data, labels = load_and_preprocess_dataset(dataset_path)\n",
    "\n",
    "# Splitingt the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc178e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "596939ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using VGG16 as a base model\n",
    "base_model = VGG16(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freezing the convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36eb5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model on top\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "595815e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.6791 - accuracy: 0.6292 - val_loss: 0.4496 - val_accuracy: 0.7857\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.4686 - accuracy: 0.7596 - val_loss: 0.3544 - val_accuracy: 0.8214\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.4307 - accuracy: 0.7955 - val_loss: 0.3352 - val_accuracy: 0.8214\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.3891 - accuracy: 0.8135 - val_loss: 0.3390 - val_accuracy: 0.8214\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.3736 - accuracy: 0.8225 - val_loss: 0.3329 - val_accuracy: 0.8393\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.3738 - accuracy: 0.8112 - val_loss: 0.3420 - val_accuracy: 0.8393\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.3223 - accuracy: 0.8584 - val_loss: 0.3578 - val_accuracy: 0.7857\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.3148 - accuracy: 0.8764 - val_loss: 0.4372 - val_accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2886 - accuracy: 0.8854 - val_loss: 0.4367 - val_accuracy: 0.7768\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.3147 - accuracy: 0.8607 - val_loss: 0.4053 - val_accuracy: 0.8036\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2584 - accuracy: 0.8854 - val_loss: 0.3721 - val_accuracy: 0.8125\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2710 - accuracy: 0.8831 - val_loss: 0.3473 - val_accuracy: 0.8393\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2310 - accuracy: 0.9034 - val_loss: 0.3503 - val_accuracy: 0.8393\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2763 - accuracy: 0.8831 - val_loss: 0.3279 - val_accuracy: 0.8125\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.2589 - accuracy: 0.8921 - val_loss: 0.3403 - val_accuracy: 0.8304\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.2430 - accuracy: 0.8809 - val_loss: 0.3477 - val_accuracy: 0.8036\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.2053 - accuracy: 0.9146 - val_loss: 0.3543 - val_accuracy: 0.7946\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.2233 - accuracy: 0.9101 - val_loss: 0.3604 - val_accuracy: 0.7946\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2257 - accuracy: 0.9056 - val_loss: 0.3702 - val_accuracy: 0.8036\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1926 - accuracy: 0.9326 - val_loss: 0.3557 - val_accuracy: 0.8125\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1920 - accuracy: 0.9281 - val_loss: 0.3555 - val_accuracy: 0.8304\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1964 - accuracy: 0.9169 - val_loss: 0.3474 - val_accuracy: 0.8304\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1969 - accuracy: 0.9258 - val_loss: 0.3577 - val_accuracy: 0.8304\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.2014 - accuracy: 0.9146 - val_loss: 0.3544 - val_accuracy: 0.8304\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1859 - accuracy: 0.9371 - val_loss: 0.3774 - val_accuracy: 0.8125\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1853 - accuracy: 0.9124 - val_loss: 0.3997 - val_accuracy: 0.8214\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1810 - accuracy: 0.9326 - val_loss: 0.4329 - val_accuracy: 0.8036\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1839 - accuracy: 0.9213 - val_loss: 0.3774 - val_accuracy: 0.8214\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1552 - accuracy: 0.9528 - val_loss: 0.3670 - val_accuracy: 0.8214\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1794 - accuracy: 0.9303 - val_loss: 0.3675 - val_accuracy: 0.8214\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with adjusted learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# Train the model with data augmentation\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "                    epochs=epochs, \n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5febc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 993ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "predictions = (model.predict(X_val) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "517bce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85        64\n",
      "           1       0.80      0.77      0.79        48\n",
      "\n",
      "    accuracy                           0.82       112\n",
      "   macro avg       0.82      0.82      0.82       112\n",
      "weighted avg       0.82      0.82      0.82       112\n",
      "\n",
      "Accuracy: 82.14%\n"
     ]
    }
   ],
   "source": [
    "# Print classification report and accuracy\n",
    "print(classification_report(y_val, predictions))\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
