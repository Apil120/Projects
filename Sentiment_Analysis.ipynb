{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5151670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (10.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.2 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 41.0/300.2 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 112.6/300.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 174.1/300.2 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 276.5/300.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 300.2/300.2 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install textblob \n",
    "#!pip install wordcloud\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d517620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary pachages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')#Used for cleaner and more visualing appealing plots\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94ea485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vaccination_tweets.csv')#Reading the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf71c6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11020 entries, 0 to 11019\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                11020 non-null  int64 \n",
      " 1   user_name         11020 non-null  object\n",
      " 2   user_location     8750 non-null   object\n",
      " 3   user_description  10340 non-null  object\n",
      " 4   user_created      11020 non-null  object\n",
      " 5   user_followers    11020 non-null  int64 \n",
      " 6   user_friends      11020 non-null  int64 \n",
      " 7   user_favourites   11020 non-null  int64 \n",
      " 8   user_verified     11020 non-null  bool  \n",
      " 9   date              11020 non-null  object\n",
      " 10  text              11020 non-null  object\n",
      " 11  hashtags          8438 non-null   object\n",
      " 12  source            11019 non-null  object\n",
      " 13  retweets          11020 non-null  int64 \n",
      " 14  favorites         11020 non-null  int64 \n",
      " 15  is_retweet        11020 non-null  bool  \n",
      "dtypes: bool(2), int64(6), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()#Displaying informtion about the data in the DatFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27f1ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "user_name              0\n",
       "user_location       2270\n",
       "user_description     680\n",
       "user_created           0\n",
       "user_followers         0\n",
       "user_friends           0\n",
       "user_favourites        0\n",
       "user_verified          0\n",
       "date                   0\n",
       "text                   0\n",
       "hashtags            2582\n",
       "source                 1\n",
       "retweets               0\n",
       "favorites              0\n",
       "is_retweet             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()#Displaying the information of empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3a23bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_name', 'user_location', 'user_description', 'user_created',\n",
       "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
       "       'date', 'text', 'hashtags', 'source', 'retweets', 'favorites',\n",
       "       'is_retweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns#Checking the names of columns in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa3fd455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Same folks said daikon paste could treat a cyt...\n",
       "1  While the world has been on the wrong side of ...\n",
       "2  #coronavirus #SputnikV #AstraZeneca #PfizerBio...\n",
       "3  Facts are immutable, Senator, even when you're...\n",
       "4  Explain to me again why we need a vaccine @Bor..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = df.drop(['id', 'user_name', 'user_location', 'user_description', 'user_created',\n",
    "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
    "       'date', 'hashtags', 'source', 'retweets', 'favorites',\n",
    "       'is_retweet'], axis=1)#Removing the un-necessary columns from the df\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85eadfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11020 entries, 0 to 11019\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11020 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "text_df.info()#Deisplaying the info of the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3d38c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a processing function fr the newly formed datset\n",
    "def data_processing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https\\S+|www\\S+https\\S+\", '',text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@w+|\\#','',text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_text = [w for w in text_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de54629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the processing function to each element in the 'text' column\n",
    "text_df['text'] = text_df['text'].apply(data_processing)\n",
    "\n",
    "# Dropping duplicate rows based on the 'text' column\n",
    "text_df = text_df.drop_duplicates('text')\n",
    "\n",
    "# Initialize a PorterStemmer for stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#function for stemming that will be applied to each row of the 'text' column\n",
    "def stemming(data):\n",
    "    # Apply stemming to each word in the text\n",
    "    stemmed_text = [stemmer.stem(word) for word in data]\n",
    "    return stemmed_text\n",
    "\n",
    "#USing the stemming function to each element in the 'text' column\n",
    "text_df['text'] = text_df['text'].apply(lambda x: stemming(word_tokenize(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e1cf06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[folk, said, daikon, past, could, treat, cytok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[world, wrong, side, histori, year, hope, bigg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[coronaviru, sputnikv, astrazeneca, pfizerbion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[fact, immut, senat, even, your, ethic, sturdi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[explain, need, vaccin, borisjohnson, matthanc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [folk, said, daikon, past, could, treat, cytok...\n",
       "1  [world, wrong, side, histori, year, hope, bigg...\n",
       "2  [coronaviru, sputnikv, astrazeneca, pfizerbion...\n",
       "3  [fact, immut, senat, even, your, ethic, sturdi...\n",
       "4  [explain, need, vaccin, borisjohnson, matthanc..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()#Displaying the new dataset after removing the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e7cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10543 entries, 0 to 11019\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10543 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 164.7+ KB\n"
     ]
    }
   ],
   "source": [
    "text_df.info()#Info of the new dataset without duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef42294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(words_list):\n",
    "    # Joins the list of words into a single string\n",
    "    text = ' '.join(words_list)\n",
    "    # Calculate polarity using TextBlob\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "text_df['polarity'] = text_df['text'].apply(polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3453d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(label):#applying the sentiment and giving it numeric labels\n",
    "    if label <0:\n",
    "        return \"Negative\"\n",
    "    elif label ==0:\n",
    "        return \"Neutral\"\n",
    "    elif label>0:\n",
    "        return \"Positive\"\n",
    "text_df['sentiment'] = text_df['polarity'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8431391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of words back to a string in the 'text' column\n",
    "text_df['text'] = text_df['text'].apply(lambda x: ' '.join(x))\n",
    "# Use CountVectorizer on the modified 'text' column\n",
    "vect = CountVectorizer(ngram_range=(1, 2)).fit(text_df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d385773",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_df['text']\n",
    "Y = text_df['sentiment']\n",
    "X = vect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfb70cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d180af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "model_pred = model.predict(x_test)\n",
    "model_acc = accuracy_score(model_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0da34648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  65   93   31]\n",
      " [   2 1299    1]\n",
      " [   7   74  537]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.34      0.49       189\n",
      "     Neutral       0.89      1.00      0.94      1302\n",
      "    Positive       0.94      0.87      0.90       618\n",
      "\n",
      "    accuracy                           0.90      2109\n",
      "   macro avg       0.90      0.74      0.78      2109\n",
      "weighted avg       0.90      0.90      0.89      2109\n",
      "\n",
      "Accuracy: 90.14%\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, model_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, model_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, model_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")#Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700e10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
